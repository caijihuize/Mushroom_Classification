{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T11:30:42.736586Z",
     "iopub.status.busy": "2025-04-06T11:30:42.736236Z",
     "iopub.status.idle": "2025-04-06T11:30:43.243982Z",
     "shell.execute_reply": "2025-04-06T11:30:43.243015Z",
     "shell.execute_reply.started": "2025-04-06T11:30:42.736554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/mushroom\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# 使用KaggleHub下载数据集\n",
    "dataset_name = \"huizecai/mushroom\"\n",
    "path = kagglehub.dataset_download(dataset_name)\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T11:30:43.245375Z",
     "iopub.status.busy": "2025-04-06T11:30:43.245115Z",
     "iopub.status.idle": "2025-04-06T11:30:59.968631Z",
     "shell.execute_reply": "2025-04-06T11:30:59.967694Z",
     "shell.execute_reply.started": "2025-04-06T11:30:43.245351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5698 files belonging to 36 classes.\n",
      "Using 5129 files for training.\n",
      "Using 569 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset_path = path + '/archive/data'\n",
    "label_path = path + '/archive/label.txt'\n",
    "\n",
    "# 加载和准备图像数据集\n",
    "train_dataset, validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=dataset_path,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    subset='both',\n",
    "    label_mode='categorical',\n",
    "    seed=44\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T11:30:59.970867Z",
     "iopub.status.busy": "2025-04-06T11:30:59.970512Z",
     "iopub.status.idle": "2025-04-06T11:30:59.976236Z",
     "shell.execute_reply": "2025-04-06T11:30:59.975570Z",
     "shell.execute_reply.started": "2025-04-06T11:30:59.970834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_MobileNetV1():\n",
    "  # 初始化基础模型\n",
    "  pre_trained_model = tf.keras.applications.MobileNet(\n",
    "      input_shape=(224, 224, 3),\n",
    "      include_top=False,\n",
    "      weights='imagenet'\n",
    "  )\n",
    "\n",
    "  # 冻结基础模型的权重\n",
    "  for layer in pre_trained_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "  x = tf.keras.applications.mobilenet.preprocess_input(pre_trained_model.input)\n",
    "\n",
    "  # 添加自定义顶层分类器\n",
    "  x = pre_trained_model(x)\n",
    "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "  x = tf.keras.layers.Dropout(0.5)(x)\n",
    "  x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "  x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "  predictions = tf.keras.layers.Dense(36, activation='softmax')(x)\n",
    "\n",
    "  # 构建最终模型\n",
    "  MobileNetV1 = tf.keras.models.Model(inputs=pre_trained_model.input, outputs=predictions)\n",
    "\n",
    "  return MobileNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T11:30:59.994389Z",
     "iopub.status.busy": "2025-04-06T11:30:59.994083Z",
     "iopub.status.idle": "2025-04-06T11:31:00.008175Z",
     "shell.execute_reply": "2025-04-06T11:31:00.007467Z",
     "shell.execute_reply.started": "2025-04-06T11:30:59.994360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def record_training_errors(model, dataset_path, output_file='error_images.txt'):\n",
    "    \"\"\"\n",
    "    使用与训练一致的方式加载数据集，并记录预测错误的图片路径\n",
    "    \"\"\"\n",
    "    # 加载数据集\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=dataset_path,\n",
    "        image_size=(224, 224, 3),\n",
    "        batch_size=32,\n",
    "        label_mode='categorical',\n",
    "        shuffle=False  # 确保顺序一致\n",
    "    )\n",
    "    \n",
    "    error_records = []\n",
    "    total_images = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    # 使用tqdm显示进度条\n",
    "    for images, labels in tqdm(dataset, desc=\"Processing dataset\", unit=\"batch\"):\n",
    "        # 进行预测\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        predicted_classes = tf.argmax(predictions, axis=1)\n",
    "        true_classes = tf.argmax(labels, axis=1)\n",
    "        \n",
    "        # 找出预测错误的索引\n",
    "        incorrect_indices = tf.where(predicted_classes != true_classes).numpy().flatten()\n",
    "        \n",
    "        # 记录错误路径\n",
    "        for idx in incorrect_indices:\n",
    "            img_path = dataset.file_paths[idx]\n",
    "            true_class = dataset.class_names[true_classes[idx]]\n",
    "            pred_class = dataset.class_names[predicted_classes[idx]]\n",
    "            error_record = f\"{img_path}\\t真实类别: {true_class}\\t预测类别: {pred_class}\"\n",
    "            error_records.append(error_record)\n",
    "            total_errors += 1\n",
    "        \n",
    "        total_images += len(images)\n",
    "    \n",
    "    # 将错误记录写入文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(error_records))\n",
    "    \n",
    "    print(f\"总图片数：{total_images}，错误预测数：{total_errors}，错误率：{total_errors/total_images:.2%}\")\n",
    "    print(f\"错误预测的图片路径已记录到：{output_file}\")\n",
    "    \n",
    "    return error_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T11:31:00.009272Z",
     "iopub.status.busy": "2025-04-06T11:31:00.009024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model = get_MobileNetV1()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_dataset,validation_data=validation_dataset, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 记录预测错误的图片\n",
    "record_training_errors(model, dataset_path, output_file='error_images.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# 图像预处理函数\n",
    "def preprocess_image(image_url, target_size=(224, 224)):\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(\"无法从链接加载图像，请检查链接是否有效！\")\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    image = image.resize(target_size)\n",
    "    image_array = np.array(image)\n",
    "    if image_array.shape[-1] != 3:\n",
    "        image_array = np.stack((image_array,) * 3, axis=-1)\n",
    "    image_array = tf.keras.applications.mobilenet_v2.preprocess_input(image_array)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    return image_array, image\n",
    "\n",
    "# 预测函数（输出前 k 个预测结果）\n",
    "def predict_top_k_from_url(model, image_url, class_names, top_k=10):\n",
    "    # 预处理图像\n",
    "    image_array, original_image = preprocess_image(image_url)\n",
    "    \n",
    "    # 使用模型进行预测\n",
    "    predictions = model.predict(image_array)[0]  # 获取预测结果（形状为 [num_classes]）\n",
    "    \n",
    "    # 获取前 k 个最高概率的索引\n",
    "    top_k_indices = np.argsort(predictions)[::-1][:top_k]\n",
    "    \n",
    "    # 获取前 k 个类别和对应的置信度\n",
    "    top_k_labels = [class_names[i] for i in top_k_indices]\n",
    "    top_k_confidences = [predictions[i] * 100 for i in top_k_indices]  # 转换为百分比\n",
    "    \n",
    "    # 可视化结果\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(\"Top Predictions\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印前 k 个预测结果\n",
    "    print(\"Top Predictions:\")\n",
    "    for label, confidence in zip(top_k_labels, top_k_confidences):\n",
    "        print(f\"  {label}: {confidence:.2f}%\")\n",
    "    \n",
    "    return top_k_labels, top_k_confidences\n",
    "\n",
    "# 测试图片链接\n",
    "image_url = \"https://th.bing.com/th/id/OIP.1Bq2Px2DKc6YXem5eABF7QHaFj?w=252&h=189&c=7&r=0&o=5&dpr=1.3&pid=1.7\"\n",
    "\n",
    "# 输出前 10 个预测结果\n",
    "top_k_labels, top_k_confidences = predict_top_k_from_url(model, image_url, class_names, top_k=10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11387971,
     "datasetId": 6602109,
     "sourceId": 11007503,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
